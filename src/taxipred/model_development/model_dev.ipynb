{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e61c262",
   "metadata": {},
   "source": [
    "### Load Cleaned Datasets\n",
    "\n",
    "In this step, we load the cleaned and processed datasets produced during the EDA phase:\n",
    "\n",
    "- **df_train**: Used for training and evaluating machine learning models  \n",
    "- **df_predict**: Contains trips without a known price and will be used for final predictions\n",
    "\n",
    "Successful loading confirms that the data pipeline from EDA to model development is working as intended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6226a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('../data/df_train.csv')\n",
    "df_predict = pd.read_csv('../data/df_predict.csv')\n",
    "\n",
    "print(f'✅ Success: Training data loaded with {df_train.shape[0]} rows.')\n",
    "print(f'✅ Success: Prediction data loaded with {df_predict.shape[0]} rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb8ddda",
   "metadata": {},
   "source": [
    "### Sanity Check: Training Data Validation\n",
    "\n",
    "Before starting model training, we perform a final sanity check on the cleaned training dataset.  \n",
    "The purpose of this step is to ensure that:\n",
    "\n",
    "- The data has been loaded correctly\n",
    "- The dataset structure matches expectations\n",
    "- There are no remaining missing values that could break model training\n",
    "- All features are ready for use in a machine learning pipeline\n",
    "\n",
    "This validation step helps confirm that the output from the EDA and data cleaning phase is reliable and suitable for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd939baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.head())\n",
    "display(df_train.info())\n",
    "\n",
    "print('\\nMissing values in training data:')\n",
    "print(df_train.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64af367",
   "metadata": {},
   "source": [
    "### Define Features and Target Variable\n",
    "\n",
    "In this step, we separate the dataset into:\n",
    "\n",
    "- **Features (X):** All input variables used by the model except the target variable (label)\n",
    "- **Target (y):** The variable we want to predict\n",
    "\n",
    "We use a log-transformed version of the trip price (`Trip_Price_log`) as the target variable to reduce skewness and improve model stability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f21ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop(columns=['Trip_Price', 'Trip_Price_log'])\n",
    "y = df_train['Trip_Price_log']\n",
    "\n",
    "print('Feature matrix shape:', X.shape)\n",
    "print('Target vector shape:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24705c7",
   "metadata": {},
   "source": [
    "### Train–Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918faab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f'{X_train.shape = }')\n",
    "print(f'{X_test.shape = }')\n",
    "print(f'{y_train.shape = }')\n",
    "print(f'{y_test.shape = }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a306d9ce",
   "metadata": {},
   "source": [
    "### “Feature Scaling (StandardScaler)”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de988a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('Scaled shapes:', X_train_scaled.shape, X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680f8253",
   "metadata": {},
   "source": [
    "### Baseline Model (Median Predictor)\n",
    "\n",
    "Before testing machine learning models, we establish a simple baseline.\n",
    "The baseline predicts the **median** value of the target variable for all trips.\n",
    "\n",
    "Any trained model must outperform this baseline to be considered useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a10637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "baseline_pred = np.full(shape=len(y_test), fill_value=np.median(y_train))\n",
    "\n",
    "mae = mean_absolute_error(y_test, baseline_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, baseline_pred))\n",
    "r2 = r2_score(y_test, baseline_pred)\n",
    "\n",
    "print('Baseline (Median) performance on log target:')\n",
    "print(f'MAE:  {mae:.4f}')\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'R2:   {r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e897b9",
   "metadata": {},
   "source": [
    "## Linear Regression Model\n",
    "\n",
    "Linear Regression is used as the first machine learning model due to its simplicity\n",
    "and interpretability. It serves as a reference point before applying more complex models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f989f73",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7449bf",
   "metadata": {},
   "source": [
    "### Predict & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab0006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "y_preds = lr_model.predict(X_test_scaled)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_preds))\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "r2 = r2_score(y_test, y_preds)\n",
    "\n",
    "print('--- Linear Regression ---')\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'MAE:  {mae:.4f}')\n",
    "print(f'R2:   {r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104791d",
   "metadata": {},
   "source": [
    "### Final Predictions on Unseen Data\n",
    "\n",
    "After training and evaluating the Linear Regression model using a train–test split on the training dataset, the model is applied to a separate prediction dataset (`df_predict`).\n",
    "\n",
    "This dataset does not contain target values and is therefore not used for model evaluation. Instead, it represents unseen data for which the trained model generates final trip price predictions.\n",
    "\n",
    "Predictions are produced on the log-transformed scale and then converted back to the original price scale before being stored in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a76efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_log = lr_model.predict(df_predict[X.columns])\n",
    "predict_price = np.exp(predict_log)\n",
    "df_predict['Trip_Price_pred'] = predict_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4273109",
   "metadata": {},
   "source": [
    "### Linear Regression Interpretation\n",
    "\n",
    "Linear Regression significantly outperformed the baseline model.\n",
    "The positive R² score indicates that the model explains a substantial portion\n",
    "of the variance in the log-transformed trip price.\n",
    "\n",
    "This confirms that the engineered features capture meaningful pricing patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0801962d",
   "metadata": {},
   "source": [
    "### Random Forest Regressor\n",
    "\n",
    "Random Forest is evaluated to capture non-linear relationships and feature interactions.\n",
    "Because it is tree-based, it does not require feature scaling, so we train it on the original\n",
    "(unscaled) feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed7970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "X_train_rf = X_train\n",
    "X_test_rf = X_test\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train_rf, y_train)\n",
    "rf_preds = rf_model.predict(X_test_rf)\n",
    "\n",
    "mae = mean_absolute_error(y_test, rf_preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, rf_preds))\n",
    "r2 = r2_score(y_test, rf_preds)\n",
    "\n",
    "print('--- Random Forest ---')\n",
    "print(f'MAE:  {mae:.4f}')\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'R2:   {r2:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429819cf",
   "metadata": {},
   "source": [
    "### Random Forest Interpretation\n",
    "\n",
    "Random Forest was evaluated to capture non-linear pricing effects and feature\n",
    "interactions. Compared to Linear Regression, the model achieved lower error\n",
    "metrics and a higher R² score.\n",
    "\n",
    "This indicates that non-linear relationships contribute to improved predictive\n",
    "performance. Based on these results, Random Forest was selected as the final\n",
    "model due to its superior overall accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4861979",
   "metadata": {},
   "source": [
    "### Final Model Selection\n",
    "\n",
    "Linear Regression was used as a reference model due to its simplicity and\n",
    "interpretability. Random Forest achieved the best overall performance with\n",
    "lower error metrics and a higher R² score.\n",
    "\n",
    "Therefore, Random Forest was selected as the final model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41acf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "\n",
    "rf_final = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_final.fit(X, y)\n",
    "\n",
    "\n",
    "joblib.dump(rf_final, '../backend/random_forest_model.joblib')\n",
    "print('Saved model to: ../backend/random_forest_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taxipred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
